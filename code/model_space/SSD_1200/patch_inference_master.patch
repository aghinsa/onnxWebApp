Binary files ../../../../inference-master/v0.5/classification_and_detection/python/models/__pycache__/ssd_r34.cpython-36.pyc and ./inference-master/v0.5/classification_and_detection/python/models/__pycache__/ssd_r34.cpython-36.pyc differ
diff -ruN ../../../../inference-master/v0.5/classification_and_detection/python/models/ssd_r34.py ./inference-master/v0.5/classification_and_detection/python/models/ssd_r34.py
--- ../../../../inference-master/v0.5/classification_and_detection/python/models/ssd_r34.py	2020-02-11 00:55:23.061792948 +0530
+++ ./inference-master/v0.5/classification_and_detection/python/models/ssd_r34.py	2020-02-11 01:57:48.998961000 +0530
@@ -253,7 +253,7 @@
         backbone="resnet34",
         model_path="./resnet34-333f7ec4.pth",
         strides=[3, 3, 2, 2, 2, 2],
-        extract_shapes=False,
+        extract_shapes=True,
     ):
 
         super(SSD_R34, self).__init__()
@@ -287,10 +287,7 @@
 
         self.loc = nn.ModuleList(self.loc)
         self.conf = nn.ModuleList(self.conf)
-        if not extract_shapes:
-            self.size = (1200, 1200)
-            dboxes = dboxes_R34_coco(list(self.size), [3, 3, 2, 2, 2, 2])
-            self.encoder = Encoder(dboxes)
+
         # intitalize all weights
         self._init_weights()
         self.device = 1
@@ -382,22 +379,6 @@
                 if param.dim() > 1:
                     nn.init.xavier_uniform_(param)
 
-    # Shape the classifier to the view of bboxes
-    def bbox_view(self, src, loc, conf, extract_shapes=False):
-        ret = []
-        features_shapes = []
-        for s, l, c in zip(src, loc, conf):
-            ret.append(
-                (l(s).view(s.size(0), 4, -1), c(s).view(s.size(0), self.label_num, -1))
-            )
-            # extract shapes for prior box initliziation
-            if extract_shapes:
-                ls = l(s)
-                features_shapes.append([ls.shape[2], ls.shape[3]])
-        locs, confs = list(zip(*ret))
-        locs, confs = torch.cat(locs, 2).contiguous(), torch.cat(confs, 2).contiguous()
-        return locs, confs, features_shapes
-
     def forward(self, data):
         layers = self.model(data)
 
@@ -410,14 +391,33 @@
             additional_results.append(x)
 
         src = [*layers, *additional_results]
+        results = src
+        return results
+
+
+class SSD_R34_POST(SSD_R34):
+    def __init__(self, src):
+        super().__init__()
         # Feature maps sizes depend on the image size. For 300x300 with strides=[1,1,2,2,2,1] it is 38x38x4, 19x19x6, 10x10x6, 5x5x6, 3x3x4, 1x1x4
         locs, confs, features_shapes = self.bbox_view(
-            src, self.loc, self.conf, extract_shapes=self.extract_shapes
+            src, self.loc, self.conf, extract_shapes=True
         )
-        if self.extract_shapes:
-            return locs, confs, features_shapes
-        else:
-            # For SSD 300 with strides=[1,1,2,2,2,1] , shall return nbatch x 8732 x {nlabels, nlocs} results
-            results = self.encoder.decode_batch(locs, confs, 0.50, 200)  # [0]
-            return results  # locs, confs,features_shapes
+        self.results = (locs, confs, features_shapes)
+        # return locs, confs, features_shapes
+
+    def output(self):
+        return self.results
+
+    def bbox_view(self, src, loc, conf, extract_shapes=False):
+        ret = []
+        features_shapes = []
+        for s, l, c in zip(src, loc, conf):
+            ret.append((l(s).view(s.size(0), 4, -1), c(s).view(s.size(0), 81, -1)))
+            # extract shapes for prior box initliziation
+            if extract_shapes:
+                ls = l(s)
+                features_shapes.append([ls.shape[2], ls.shape[3]])
+        locs, confs = list(zip(*ret))
+        locs, confs = torch.cat(locs, 2).contiguous(), torch.cat(confs, 2).contiguous()
+        return locs, confs, features_shapes
 
